{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DueuR0iKywRA"
      },
      "outputs": [],
      "source": [
        "# !pip install transformers[Sentencepiece] sentence-transformers faiss-cpu datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Gq3LmMaYoW",
        "outputId": "b2a97099-86d5-406b-bcf2-7e25423b92b3"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "from datasets import load_dataset, concatenate_datasets \n",
        "import evaluate\n",
        "from transformers import (\n",
        "    T5Tokenizer, \n",
        "    T5ForConditionalGeneration\n",
        "    )\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQKxWY-2axMr"
      },
      "outputs": [],
      "source": [
        "from qasper_utils import get_QAE2, get_all_paragraphs, get_all_questions\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vUIztV3ext7"
      },
      "outputs": [],
      "source": [
        "# !cp /content/drive/MyDrive/multi-qa-distilbert-dot-v1-qasper-retriever.zip multi-qa-distilbert-dot-v1-qasper-retriever.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqfmcW4Tf6MF"
      },
      "outputs": [],
      "source": [
        "# !unzip multi-qa-distilbert-dot-v1-qasper-retriever.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQqUiC7Xt6OH"
      },
      "outputs": [],
      "source": [
        "# !cp /content/drive/MyDrive/flant5_reader.zip flant5_reader.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOgs9U-quIt5"
      },
      "outputs": [],
      "source": [
        "# !unzip flant5_reader.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cXg4pxmZTut"
      },
      "outputs": [],
      "source": [
        "dev_path = \"/content/drive/MyDrive/qasper-dev-v0.3.json\"\n",
        "test_path = \"/content/drive/MyDrive/qasper-test-v0.3.json\"\n",
        "\n",
        "with open(dev_path, 'r') as f:\n",
        "    dev_data = json.load(f)\n",
        "    \n",
        "with open(test_path, 'r') as f:\n",
        "    test_data = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDAfZKZgbwkF"
      },
      "outputs": [],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "retriever_model = SentenceTransformer(\"/content/content/multi-qa-distilbert-dot-v1-qasper-retriever\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8lVwQZa1uWrj"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = \"/content/content/flant5_reader\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_checkpoint)\n",
        "reader_model = T5ForConditionalGeneration.from_pretrained(model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IM7cWTMvgbR"
      },
      "outputs": [],
      "source": [
        "def get_answer(question, context):\n",
        "  input_text = f\"question: {question}  context: {context} </s>\"\n",
        "  features = tokenizer([input_text], return_tensors='pt')\n",
        "\n",
        "  output = reader_model.generate(input_ids=features['input_ids'], \n",
        "               attention_mask=features['attention_mask'], max_new_tokens=128)\n",
        "\n",
        "  return tokenizer.decode(output[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Z6Rby5Rn-bt"
      },
      "outputs": [],
      "source": [
        "dev_paragraphs = get_all_paragraphs(dev_data)\n",
        "dev_paragraph_df = pd.DataFrame(dev_paragraphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ0SoTGVosNm",
        "outputId": "0bded9dc-4bd9-479d-fa5d-1f72a6630fe6"
      },
      "outputs": [],
      "source": [
        "dev_indexes = {}\n",
        "dev_paragraph_dict = {}\n",
        "for name, group in tqdm(dev_paragraph_df.groupby(\"paper_id\")):\n",
        "  paper_para = group[\"paragraph\"].values\n",
        "  dev_paragraph_dict[name] = paper_para.tolist()\n",
        "  dev_embed_array = retriever_model.encode(paper_para)\n",
        "  d = dev_embed_array.shape[1]\n",
        "  dev_index = faiss.IndexFlatIP(d)\n",
        "  dev_index.add(dev_embed_array)\n",
        "  dev_indexes[name]= dev_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hbvthaYhT3j"
      },
      "outputs": [],
      "source": [
        "dev_questions = get_all_questions(dev_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bnh3SSHFsywK"
      },
      "outputs": [],
      "source": [
        "dev_questions_df = pd.DataFrame(dev_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q9Bhxm4w4Un",
        "outputId": "2ffa35d2-503a-495c-f268-b825363fad2b"
      },
      "outputs": [],
      "source": [
        "dev_predictions = [] \n",
        "for name,group in tqdm(dev_questions_df.groupby(\"paper_id\")):\n",
        "  for idx,row in group.iterrows():\n",
        "    question = row[\"question\"]\n",
        "    xq = retriever_model.encode([question])\n",
        "    _, I = dev_indexes[name].search(xq,2)\n",
        "    evidence = [dev_paragraph_dict[name][i] for i in I[0]]\n",
        "    context = \" \".join(evidence)\n",
        "    answer = get_answer(question, context)\n",
        "    dev_predictions.append(\n",
        "        {\n",
        "            \"question_id\": row[\"question_id\"],\n",
        "            \"predicted_answer\": answer,\n",
        "            \"predicted_evidence\": evidence\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AV15iZBmTE5M"
      },
      "outputs": [],
      "source": [
        "cleaned_dev_predictions = []\n",
        "for dev_pred in dev_predictions:\n",
        "  cleaned_dev_predictions.append(\n",
        "      {\n",
        "          \"question_id\": dev_pred[\"question_id\"],\n",
        "          \"predicted_answer\": dev_pred[\"predicted_answer\"].replace(\"<pad>\",\"\").replace(\"</s>\", \"\").strip(),\n",
        "          \"predicted_evidence\": dev_pred[\"predicted_evidence\"]\n",
        "      }\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RctZ-w8myxIK"
      },
      "outputs": [],
      "source": [
        "with open(\"cleaned_dev_predictions.jsonl\", 'w') as out:\n",
        "    for pred in cleaned_dev_predictions:\n",
        "        jout = json.dumps(pred) + '\\n'\n",
        "        out.write(jout)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5y9eywzDSdDJ"
      },
      "outputs": [],
      "source": [
        "dev_predictions_df = pd.DataFrame(cleaned_dev_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wclxijySkka",
        "outputId": "9755f0c6-3b27-44c3-a8a4-c29d0718f31f"
      },
      "outputs": [],
      "source": [
        "sum(dev_predictions_df[\"predicted_answer\"]==104)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1W7vHB9R5UX"
      },
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E1VmwA1R7a6"
      },
      "outputs": [],
      "source": [
        "test_paragraphs = get_all_paragraphs(test_data)\n",
        "test_paragraph_df = pd.DataFrame(test_paragraphs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9O9XcN37R9O4",
        "outputId": "8b59f50c-e8e0-4397-900d-1d29e580a46a"
      },
      "outputs": [],
      "source": [
        "test_indexes = {}\n",
        "test_paragraph_dict = {}\n",
        "for name, group in tqdm(test_paragraph_df.groupby(\"paper_id\")):\n",
        "  paper_para = group[\"paragraph\"].values\n",
        "  test_paragraph_dict[name] = paper_para.tolist()\n",
        "  test_embed_array = retriever_model.encode(paper_para)\n",
        "  d = test_embed_array.shape[1]\n",
        "  test_index = faiss.IndexFlatIP(d)\n",
        "  test_index.add(test_embed_array)\n",
        "  test_indexes[name]= test_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCKzcuCYSExZ"
      },
      "outputs": [],
      "source": [
        "test_questions = get_all_questions(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8vR6-ZG3SHye"
      },
      "outputs": [],
      "source": [
        "test_questions_df = pd.DataFrame(test_questions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfC77pt0SMF3",
        "outputId": "1ad5a2da-587e-43de-847e-9ccf1e1f84ef"
      },
      "outputs": [],
      "source": [
        "test_predictions = [] \n",
        "for name,group in tqdm(test_questions_df.groupby(\"paper_id\")):\n",
        "  for idx,row in group.iterrows():\n",
        "    question = row[\"question\"]\n",
        "    xq = retriever_model.encode([question])\n",
        "    _, I = test_indexes[name].search(xq,2)\n",
        "    evidence = [test_paragraph_dict[name][i] for i in I[0]]\n",
        "    context = \" \".join(evidence)\n",
        "    answer = get_answer(question, context)\n",
        "    test_predictions.append(\n",
        "        {\n",
        "            \"question_id\": row[\"question_id\"],\n",
        "            \"predicted_answer\": answer.replace(\"<pad>\",\"\").replace(\"</s>\", \"\").strip(),\n",
        "            \"predicted_evidence\": evidence\n",
        "        }\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0GHT90ySQ0B"
      },
      "outputs": [],
      "source": [
        "with open(\"cleaned_test_predictions.jsonl\", 'w') as out:\n",
        "    for pred in test_predictions:\n",
        "        jout = json.dumps(pred) + '\\n'\n",
        "        out.write(jout)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
